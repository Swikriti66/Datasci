{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOADING AND CLEANING DATASET "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_33592\\1044532615.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  cleaned_df[col].fillna(cleaned_df[col].mode()[0], inplace=True)\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_33592\\1044532615.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  cleaned_df[col].fillna(cleaned_df[col].median(), inplace=True)\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_33592\\1044532615.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  cleaned_df[col].fillna(cleaned_df[col].median(), inplace=True)\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_33592\\1044532615.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  cleaned_df[col].fillna(cleaned_df[col].median(), inplace=True)\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_33592\\1044532615.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  cleaned_df[col].fillna(cleaned_df[col].median(), inplace=True)\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_33592\\1044532615.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  cleaned_df[col].fillna(cleaned_df[col].median(), inplace=True)\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_33592\\1044532615.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  cleaned_df[col].fillna(cleaned_df[col].mode()[0], inplace=True)\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_33592\\1044532615.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  cleaned_df[col].fillna(cleaned_df[col].median(), inplace=True)\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_33592\\1044532615.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  cleaned_df[col].fillna(cleaned_df[col].mode()[0], inplace=True)\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_33592\\1044532615.py:87: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  cleaned_df[col] = pd.to_numeric(cleaned_df[col], errors='ignore')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Load the dataset\n",
    "# -------------------------------\n",
    "input_path = 'collected.csv'\n",
    "df = pd.read_csv(input_path)\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Omit rows with many missing features until we have 1000 entries\n",
    "# -------------------------------\n",
    "df['missing_count'] = df.isnull().sum(axis=1)\n",
    "df_sorted = df.sort_values('missing_count')\n",
    "cleaned_df = df_sorted.head(1000).copy()\n",
    "cleaned_df.drop(columns=['missing_count'], inplace=True)\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Drop unwanted features (columns) such as 'title' and 'address'\n",
    "# -------------------------------\n",
    "cols_to_drop = ['title', 'address']\n",
    "cleaned_df.drop(columns=cols_to_drop, errors='ignore', inplace=True)\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Handle missing values without omitting data\n",
    "# -------------------------------\n",
    "for col in cleaned_df.columns:\n",
    "    if cleaned_df[col].dtype == 'object':  \n",
    "        # Categorical column: Fill missing values with the most frequent value (mode)\n",
    "        cleaned_df[col].fillna(cleaned_df[col].mode()[0], inplace=True)\n",
    "    else:\n",
    "        # Numerical column: Fill missing values with the median\n",
    "        cleaned_df[col].fillna(cleaned_df[col].median(), inplace=True)\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Convert 'area' column to square feet without omitting the data\n",
    "# -------------------------------\n",
    "def convert_to_sqft(area):\n",
    "    if isinstance(area, str):\n",
    "        area = area.lower().strip()\n",
    "        if 'sq.m' in area:\n",
    "            num = float(area.replace('sq.m', '').strip())\n",
    "            return num * 10.7639  # Convert to square feet\n",
    "        elif 'aana' in area:\n",
    "            num = float(area.replace('aana', '').strip())\n",
    "            return num * 342.25\n",
    "        elif 'ropani' in area:\n",
    "            num = float(area.replace('ropani', '').strip())\n",
    "            return num * 5476\n",
    "        elif 'dhur' in area:\n",
    "            num = float(area.replace('dhur', '').strip())\n",
    "            return num * 182.25\n",
    "        elif 'sq.ft' in area:\n",
    "            return float(area.replace('sq.ft', '').strip())\n",
    "    return area  # Return original value if conversion fails\n",
    "\n",
    "if 'area' in cleaned_df.columns:\n",
    "    cleaned_df['area_sqft'] = cleaned_df['area'].apply(convert_to_sqft)\n",
    "    cleaned_df.drop(columns=['area'], inplace=True)\n",
    "\n",
    "# -------------------------------\n",
    "# 6. One-hot encode the 'city' column (kathmandu, lalitpur, bhaktapur)\n",
    "# -------------------------------\n",
    "if 'city' in cleaned_df.columns:\n",
    "    cleaned_df['city'] = cleaned_df['city'].astype(str).str.lower()\n",
    "    allowed_cities = ['kathmandu', 'lalitpur', 'bhaktapur']\n",
    "    cleaned_df['city'] = cleaned_df['city'].apply(lambda x: x if x in allowed_cities else 'other')\n",
    "    \n",
    "    # One-hot encode city values\n",
    "    cleaned_df['kathmandu'] = (cleaned_df['city'] == 'kathmandu').astype(int)\n",
    "    cleaned_df['lalitpur'] = (cleaned_df['city'] == 'lalitpur').astype(int)\n",
    "    cleaned_df['bhaktapur'] = (cleaned_df['city'] == 'bhaktapur').astype(int)\n",
    "    cleaned_df.drop(columns=['city'], inplace=True)  # Drop the original city column\n",
    "\n",
    "# -------------------------------\n",
    "# 7. Binary encoding of amenities (each with a separate column)\n",
    "# -------------------------------\n",
    "amenity_cols = ['parking', 'water supply', 'frontyard', 'backyard', 'lawn']\n",
    "for col in amenity_cols:\n",
    "    if col in cleaned_df.columns:\n",
    "        cleaned_df[col] = cleaned_df[col].apply(lambda x: 1 if str(x).strip().lower() in ['yes', 'true', '1'] else 0)\n",
    "\n",
    "# -------------------------------\n",
    "# 8. Convert all columns to numeric values (without omitting the data)\n",
    "# -------------------------------\n",
    "for col in cleaned_df.columns:\n",
    "    cleaned_df[col] = pd.to_numeric(cleaned_df[col], errors='ignore')\n",
    "\n",
    "# -------------------------------\n",
    "# 9. Save the cleaned dataset to a new CSV file\n",
    "# -------------------------------\n",
    "output_path= 'cleaned.csv'\n",
    "cleaned_df.to_csv(output_path,index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 18 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Title       1000 non-null   object \n",
      " 1   Address     1000 non-null   object \n",
      " 2   City        1000 non-null   object \n",
      " 3   Price       1000 non-null   int64  \n",
      " 4   Bedroom     1000 non-null   int64  \n",
      " 5   Bathroom    1000 non-null   int64  \n",
      " 6   Floors      1000 non-null   float64\n",
      " 7   Parking     1000 non-null   int64  \n",
      " 8   Face        1000 non-null   object \n",
      " 9   Year        1000 non-null   float64\n",
      " 10  Views       1000 non-null   object \n",
      " 11  Area        1000 non-null   object \n",
      " 12  Road        1000 non-null   object \n",
      " 13  Road Width  1000 non-null   object \n",
      " 14  Road Type   1000 non-null   object \n",
      " 15  Build Area  1000 non-null   object \n",
      " 16  Posted      1000 non-null   object \n",
      " 17  Amenities   1000 non-null   object \n",
      "dtypes: float64(2), int64(4), object(12)\n",
      "memory usage: 140.8+ KB\n",
      "None \n",
      "\n",
      "                                               Title  \\\n",
      "0  Grandy Gate Home : House For Sale In Budhanilk...   \n",
      "1  Shutters For Rent : Office Space For Rent In K...   \n",
      "2  SAMAKHUSI HOME : House For Sale In Samakhusi, ...   \n",
      "3  Newly Constructed : House For Sale In Imadol, ...   \n",
      "4             House For Sale In Pepsicola, Kathmandu   \n",
      "\n",
      "                           Address       City     Price  Bedroom  Bathroom  \\\n",
      "0    Na, Budhanilkantha, Kathmandu  Kathmandu  22500000        6         6   \n",
      "1      338/6, Koteshwor, Kathmandu  Kathmandu     24000        0         3   \n",
      "2  Samakhusi, Samakhusi, Kathmandu  Kathmandu  44000000        5         6   \n",
      "3   Sital height, Imadol, Lalitpur   Lalitpur  22000000        7         4   \n",
      "4         Na, Pepsicola, Kathmandu  Kathmandu  58500000        6         6   \n",
      "\n",
      "   Floors  Parking        Face    Year Views          Area  \\\n",
      "0     3.0        1  North East  2070.0    66      3.1 Aana   \n",
      "1     2.0        1        West  2052.0   719       13 Aana   \n",
      "2     3.0        1        East  2076.0   390        4 Aana   \n",
      "3     3.5        2       South  2076.0   981  0-4-2-0 Aana   \n",
      "4     3.0        2        East  2076.0   318      6.5 Aana   \n",
      "\n",
      "                    Road Road Width     Road Type Build Area        Posted  \\\n",
      "0  18 Feet / Blacktopped   18 Feet    Blacktopped   N/A Aana   1 month ago   \n",
      "1        0 Meter / Paved   0 Meter          Paved     6 Aana  7 months ago   \n",
      "2  15 Feet / Blacktopped   15 Feet    Blacktopped   N/A Aana  7 months ago   \n",
      "3    13 Feet / Gravelled   13 Feet      Gravelled  2700 Aana  4 months ago   \n",
      "4  16 Feet / Blacktopped   16 Feet    Blacktopped   N/A Aana   1 month ago   \n",
      "\n",
      "                                           Amenities  \n",
      "0                                        ['Parking']  \n",
      "1  ['Garage', 'Balcony', 'Water Well', 'Wifi', 'C...  \n",
      "2  ['Water Tank', 'Water Supply', 'Solar Water', ...  \n",
      "3  ['Balcony', 'Fencing', 'Modular Kitchen', 'TV ...  \n",
      "4                              ['Parking', 'Garage']   \n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '2.8K'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 39\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Feature scaling\u001b[39;00m\n\u001b[0;32m     38\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[1;32m---> 39\u001b[0m X_train_scaled \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m X_test_scaled \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(X_test)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Add bias term\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:319\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 319\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    322\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    323\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    324\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    325\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:918\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    903\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    904\u001b[0m             (\n\u001b[0;32m    905\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) has a `transform`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    913\u001b[0m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[0;32m    914\u001b[0m         )\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    917\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m    919\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    920\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    921\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:894\u001b[0m, in \u001b[0;36mStandardScaler.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    892\u001b[0m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m--> 894\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:930\u001b[0m, in \u001b[0;36mStandardScaler.partial_fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    898\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Online computation of mean and std on X for later scaling.\u001b[39;00m\n\u001b[0;32m    899\u001b[0m \n\u001b[0;32m    900\u001b[0m \u001b[38;5;124;03mAll of X is processed as a single batch. This is intended for cases\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    927\u001b[0m \u001b[38;5;124;03m    Fitted scaler.\u001b[39;00m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    929\u001b[0m first_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples_seen_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 930\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    932\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    933\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    934\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    935\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    936\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    937\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    938\u001b[0m n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    940\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2944\u001b[0m, in \u001b[0;36mvalidate_data\u001b[1;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[0;32m   2942\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m   2943\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m-> 2944\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2945\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m   2946\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:1055\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1053\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1054\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1055\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1056\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m   1057\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1058\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m   1059\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:839\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[0;32m    837\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    838\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 839\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    841\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    842\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    843\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '2.8K'"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"cleaned.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Data overview\n",
    "print(df.info(), \"\\n\")\n",
    "print(df.head(), \"\\n\")\n",
    "\n",
    "# Handle missing values by replacing them with the mean of the respective column\n",
    "df = df.dropna()\n",
    "\n",
    "# Drop all non-numeric features\n",
    "#df = df.select_dtypes(include=[np.number])\n",
    "\n",
    "# Select features and target\n",
    "features = ['Bedroom','Bathroom','Floors','Parking','Year','Views']\n",
    "target = 'Price'\n",
    "\n",
    "if not all(col in df.columns for col in features + [target]):\n",
    "    raise ValueError(\"Missing required columns in the dataset!\")\n",
    "\n",
    "X = df[features].values\n",
    "y = df[target].values.reshape(-1, 1)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Add bias term\n",
    "X_train_scaled = np.c_[np.ones(X_train_scaled.shape[0]), X_train_scaled]\n",
    "X_test_scaled = np.c_[np.ones(X_test_scaled.shape[0]), X_test_scaled]\n",
    "\n",
    "# Initialize parameters\n",
    "theta = np.zeros((X_train_scaled.shape[1], 1))\n",
    "\n",
    "# Gradient Descent\n",
    "def gradient_descent(X, y, theta, alpha, iterations):\n",
    "    m = len(y)\n",
    "    cost_history = []\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        predictions = X.dot(theta)\n",
    "        gradient = (1/m) * X.T.dot(predictions - y)\n",
    "        theta -= alpha * gradient\n",
    "        cost = (1/(2*m)) * np.sum((predictions - y)**2)\n",
    "        cost_history.append(cost)\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(f\"Iteration {i}: Cost {cost}\")\n",
    "\n",
    "    return theta, cost_history\n",
    "\n",
    "# Train model\n",
    "alpha, iterations = 0.01, 1000\n",
    "theta, cost_history = gradient_descent(X_train_scaled, y_train, theta, alpha, iterations)\n",
    "\n",
    "# Prediction function\n",
    "def predict(X, theta):\n",
    "    return X.dot(theta)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = predict(X_test_scaled, theta)\n",
    "\n",
    "# Model evaluation\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\nModel Evaluation:\")\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"MSE: {mse}\")\n",
    "print(f\"R² Score: {r2}\")\n",
    "\n",
    "# Plot cost function convergence\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(len(cost_history)), cost_history, color='blue')\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Cost\")\n",
    "plt.title(\"Gradient Descent Convergence\")\n",
    "plt.show()\n",
    "\n",
    "# Visualization: Actual vs Predicted Prices\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.scatterplot(x=y_test.flatten(), y=y_pred.flatten(), alpha=0.7)\n",
    "plt.xlabel(\"Actual Prices (NPR)\")\n",
    "plt.ylabel(\"Predicted Prices (NPR)\")\n",
    "plt.title(\"Actual vs Predicted House Prices\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
